import scrapy
import pickle

class PixivPicSpiderSpider(scrapy.Spider):
    name = "pixiv_pic_spider"
    allowed_domains = ["pixiv.net","i.pximg.net"]#æ·»åŠ æ–°åŸŸåä»¥ä¾¿è®¿é—®å›¾ç‰‡
    start_urls = ["https://www.pixiv.net/users/49460730"]

    def start_requests(self):
        url=self.start_urls[0]
        ##è¿™æ®µæ˜¯æ¯”è¾ƒç®€å•çš„cookieè·å¾—æ–¹å¼ï¼Œä»æµè§ˆå™¨å¤åˆ¶ç„¶åå¤„ç†
        # temp='privacy_policy_notification=0; a_type=0; b_type=1; _im_vid=01JAPXHCHQBAQZ8KXYWSVT6JGA; first_visit_datetime_pc=2024-11-03%2017%3A27%3A23; yuid_b=QTYmVGY; p_ab_id=0; p_ab_id_2=1; p_ab_d_id=571229789; jp1_ad_freq={}; privacy_policy_agreement=7; gam_ad_freq={}; _im_uid.3929=i.JpeA5JXrT-GTrzM1-qXc1w; gam_et_freq={"2628":[0,1745597715016],"2630":[0,1745597693351],"3127":[0,1745597611312],"4935":[0,1745597693353],"4936":[0,1745597611314]}; jp1_et_freq={"5078":[0,1745847728573]}; _cfuvid=3JNfX4iJ9q95N0W2GU1c_GfPHtQDxS6ixHM7NMr4LZU-1749883173131-0.0.1.1-604800000; __utmc=235335808; __utmz=235335808.1749883178.22.11.utmcsr=bing|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); cto_bundle=7mAns19ld0I4akh4R1I3eTZpQnB6VHpsdThsMGt2M1A2b0hIYk90cUNkd1hWVVdXUWklMkI1YmtFR0E0cFExa3p4ZzB5eEN2Zk9KZ003Vk5jaiUyRmJEa0RjQnZhOG1GWGlHb2RBSHlkOHV1aFEzZzluc09RTEFOSWJBUWNLZEJLQjZscFJSWnliOUxCWk5xWVN3bFNKTzYyMGhDVDRRJTNEJTNE; _gid=GA1.2.462409179.1749883495; __utma=235335808.209784871.1695634818.1749883178.1749888104.23; __cf_bm=vSEN4dLC8viqtgO2v6eDgC.r2NXmR30K1Q1JJIL6VHo-1749894855-1.0.1.1-.oA72UKSV24x5sS92YwHpuo.8HOimIQhLgUqrmTO33SxrSbEV_ELhnTM.369VjyX1NSuyxVVQYXWRREeAouwG1B66HfBK7UHtSt3CS5j4shIYi15.MIeRqy7R3ZtbcJd; __utmt=1; cf_clearance=7AKzO3yslWRzxTV8Thluvhc8iY6eQhdwnBdnHP7XUjQ-1749895377-1.2.1.1-g4oNVjJtQ5vf0aAAAzOzMn7wss1YYfcF7aG1ASMmkY9pgru5czoc8sYoFPW9qOyn.dVhQZu51qE1THaW.LpnEXSgqP_5EYJliFy1PJzdCrldF8enUSX5JQmMatFs46VM_rpaFrptSk9b_Pnj3OTKDkwWsj6Abi0BVdwrZ8ymJCZtc_CTfpqSnd7cCCNt3O67QriT7Vb6u7_LmdRtc0xRRtYtbbtrgpVlWYTlL6FXNJq5hmpl7gdCiOMluliGMNwXkZUjcF9X9S4oscJaSZglGxGOiOEpEc.PAKst9CJN0gBNqBvySvlihCo0yZBANZYInkqKQbNmHEQR926jlMo.UJZd52wKrWiH4YZW1lh0dXE; _ga=GA1.1.423436449.1695634818; device_token=bdb7d28cf3476501e93101bf92111b99; cc1=2025-06-14%2019%3A04%3A03; _gcl_au=1.1.797451785.1749895446; PHPSESSID=98873340_0xX0QpvfuVlzFEoeOTdsa5xzg1sm7nCA; c_type=27; _ga_MZ1NL4PHH0=GS2.1.s1749894614$o9$g1$t1749895466$j42$l0$h0; __utmv=235335808.|2=login%20ever=no=1^3=plan=normal=1^5=gender=male=1^9=p_ab_id=0=1^10=p_ab_id_2=1=1; __utmb=235335808.16.10.1749888104; _ga_75BBYNYN9J=GS2.1.s1749891836$o28$g1$t1749895485$j14$l0$h0; FCNEC=%5B%5B%22AKsRol-n5TgI3CjUtb300dXlRD48jVJUrZ3TiyitLcez-8jvHLR4zSHLs-RyKRuAqEMUeVjLBt9dItpc8SShaBi5yBtidQfJ8xaiS3MlVNEX-9k-1_4TY386K7Lhj_8oQ62bAUaoeKL496UPfNQ89OFgnu9PLTxo0g%3D%3D%22%5D%5D'
        # cookies = {data.split('=')[0]: data.split('=')[-1] for data in temp.split(';')}

        ## è¿™æ®µæ˜¯Playwright æ¸²æŸ“çš„ä½¿ç”¨
        # yield scrapy.Request(url=url, callback=self.parse,cookies=cookies,meta={
        #             "playwright": True  # å¼€å¯ Playwright æ¸²æŸ“
        #         })

        with open("pixiv_cookies.pkl", "rb") as f:
            cookies_list = pickle.load(f)
            print("Cookies loaded:", cookies_list)
        cookies_dict = {cookie['name']: cookie['value'] for cookie in cookies_list}

        yield scrapy.Request(url=url, callback=self.parse, meta={"selenium": 'shouCang'},cookies=cookies_dict)

    ##è¿™ä¸ªå‡½æ•°æ˜¯ç¿»é¡µé˜²æ­¢æ­»å¾ªç¯çš„å¤„ç†
    def __init__(self, *args, **kwargs):
        #è¡¨ç¤ºåœ¨è‡ªå®šä¹‰å‰ï¼Œå…ˆè°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•ï¼Œä¿è¯ Scrapy èƒ½æ­£å¸¸å·¥ä½œã€‚
        super().__init__(*args, **kwargs)
        self.visited_urls = set()  # è®°å½•è®¿é—®è¿‡çš„é¡µé¢é˜²æ­¢æ­»å¾ªç¯

    def parse(self, response):

        ##è¿™æ®µæ˜¯ç¿»é¡µé˜²æ­¢æ­»å¾ªç¯çš„å¤„ç†
        # # åŠ å…¥å½“å‰é¡µé¢åˆ°è®¿é—®è®°å½•
        # if response.url in self.visited_urls:
        #     self.logger.warning(f"é‡å¤é¡µé¢å·²è®¿é—®è¿‡ï¼š{response.url}ï¼Œè·³è¿‡")
        #     return
        # self.visited_urls.add(response.url)

        print(response.url)
        # works=response.xpath('//ul[contains(@class,"sc-bf8cea3f-1")]/li[1]/div/div[2]/a/@href').extract_first()
        work = response.xpath('//ul[contains(@class,"sc-bf8cea3f-1")]/li[2]/div/div[2]/a/@href').extract_first()
        work=response.urljoin(work)
        print(work)
        yield scrapy.Request(url=work, callback=self.parse_detail, meta={"selenium": 'pic'},cookies=response.request.cookies,headers={
        'Referer': 'https://www.pixiv.net/'  # ğŸ‘ˆ è¿™é‡Œè‡ªå®šä¹‰ Referer
    })

    def parse_detail(self, response):
        # pass
        print("ä½œå“è¯¦æƒ…é¡µé¢"+response.url)
        pic_url=response.xpath('//div[@role="presentation"]//a/@href').extract_first()#æ‰¾ä¸åˆ°ï¼Œä¾æ—§æ˜¯åŠ¨æ€æ¸²æŸ“
        print(pic_url)
        # with open("å›¾ç‰‡è¯¦æƒ…é¡µé¢.html", "w", encoding="utf-8") as f:
        #     f.write(response.text)

        ##è¿™æ®µæ˜¯éªŒè¯åŠ¨æ€æ¸²æŸ“è¢«æˆåŠŸçˆ¬ä¸‹æ¥çš„å¤„ç†
        # #ä¿å­˜ç½‘é¡µæºä»£ç 
        # with open("pixiv_rendered_selenium.html", "w", encoding="utf-8") as f:
        #     f.write(response.text)


        ##è¿™æ®µæ˜¯å¤„ç†è®¿é—®æ”¶è—é¡µé¢è·³è½¬ç™»å½•é¡µé¢å†ä¸€æ¬¡æ¨¡æ‹Ÿç™»å½•
        # å¤„ç†è¿›å…¥æ”¶è—é€»è¾‘
        # shouCang_url = response.xpath('//nav/a[contains(@href,"bookmarks")]/@href').extract_first()
        # shouCang_url = response.urljoin(shouCang_url)
        # print(shouCang_url)
        # yield scrapy.Request(url=shouCang_url, callback=self.parse_denglu, meta={'cookies': response.request.cookies})

        ##è¿™æ®µæ˜¯ç¿»é¡µé˜²æ­¢æ­»å¾ªç¯çš„å¤„ç†
        # if next_url != None:
        #     next_url = response.urljoin(next_url)
        #     # æ£€æŸ¥ä¸‹ä¸€é¡µæ˜¯å¦å·²è®¿é—®ï¼Œé¿å…æ­»å¾ªç¯
        #     if next_url not in self.visited_urls:
        #         yield scrapy.Request(url=next_url, callback=self.parse_detail, meta={'cookies': response.request.cookies})
        #     else:
        #         self.logger.info(f"ä¸‹ä¸€é¡µå·²è®¿é—®ï¼Œåœæ­¢ç¿»é¡µ: {next_url}")

    ##è¿™æ®µæ˜¯å¤„ç†è®¿é—®æ”¶è—é¡µé¢è·³è½¬ç™»å½•é¡µé¢å†ä¸€æ¬¡æ¨¡æ‹Ÿç™»å½•
    # def parse_detail(self, response):
    #     print("è¯¦æƒ…é¡µé¢"+response.url)
    #
    #
    # def parse_denglu(self, response):
    #     print("å¤„ç†ç™»å½•"+response.url)
    #     cookies = response.meta['cookies']
    #     if "return_to" in response.url:
    #         yield scrapy.Request(url=response.url, callback=self.parse_detail,cookies=cookies)




